"""
ç¾å›½ç»æµæŒ‡æ ‡è‡ªåŠ¨çˆ¬è™«ç³»ç»Ÿ - ä¸»ç¨‹åº
Flask APIæœåŠ¡ + å®šæ—¶ä»»åŠ¡è°ƒåº¦
"""

from flask import Flask, jsonify
from flask_cors import CORS
from apscheduler.schedulers.background import BackgroundScheduler
import json
import os
from datetime import datetime
import logging
import requests

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

# æ•°æ®å­˜å‚¨æ–‡ä»¶
DATA_FILE = 'data/indicators.json'

def load_data():
    """ä»æ–‡ä»¶åŠ è½½æ•°æ®"""
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_data(data):
    """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶"""
    os.makedirs('data', exist_ok=True)
    with open(DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def fetch_bls_data(series_id, name, unit='%'):
    """è·å–BLSæ•°æ®ï¼ˆCPIã€å¤±ä¸šç‡ï¼‰"""
    try:
        api_url = "https://api.bls.gov/publicAPI/v2/timeseries/data/"
        current_year = datetime.now().year
        
        payload = {
            "seriesid": [series_id],
            "startyear": str(current_year - 1),
            "endyear": str(current_year)
        }
        
        response = requests.post(api_url, json=payload, timeout=30)
        data = response.json()
        
        if data['status'] == 'REQUEST_SUCCEEDED':
            latest = data['Results']['series'][0]['data'][0]
            year = latest['year']
            month = latest['period'].replace('M', '').zfill(2)
            value = float(latest['value'])
            
            # CPIéœ€è¦è®¡ç®—å¹´åº¦é€šèƒ€ç‡
            if series_id == 'CUUR0000SA0':
                series_data = data['Results']['series'][0]['data']
                year_ago = [d for d in series_data 
                           if d['year'] == str(int(year)-1) and d['period'] == latest['period']]
                if year_ago:
                    year_ago_value = float(year_ago[0]['value'])
                    value = ((value - year_ago_value) / year_ago_value) * 100
            
            return {
                'name': name,
                'value': round(value, 1),
                'date': f"{year}-{month}-01",
                'source': 'BLS',
                'unit': unit
            }
    except Exception as e:
        logger.error(f"BLSæ•°æ®è·å–å¤±è´¥ ({name}): {e}")
    return None

def fetch_fred_data(series_id, name, unit):
    """ä»FREDè·å–æ•°æ®ï¼ˆåˆ©ç‡ã€ISMã€æ¶ˆè´¹è€…ä¿¡å¿ƒï¼‰"""
    try:
        # ä½¿ç”¨å…¬å¼€çš„FREDæ•°æ®æ¥å£
        api_url = "https://api.stlouisfed.org/fred/series/observations"
        
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦APIå¯†é’¥ï¼Œä½†æˆ‘ä»¬å…ˆç”¨æ¨¡æ‹Ÿæ•°æ®
        # å®é™…éƒ¨ç½²æ—¶éœ€è¦åœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½®
        api_key = os.environ.get('FRED_API_KEY', '')
        
        if not api_key:
            logger.warning(f"æœªé…ç½®FRED APIå¯†é’¥ï¼Œ{name}ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return None
            
        params = {
            'series_id': series_id,
            'api_key': api_key,
            'file_type': 'json',
            'sort_order': 'desc',
            'limit': 1
        }
        
        response = requests.get(api_url, params=params, timeout=30)
        data = response.json()
        
        if 'observations' in data and len(data['observations']) > 0:
            latest = data['observations'][0]
            return {
                'name': name,
                'value': round(float(latest['value']), 1),
                'date': latest['date'],
                'source': 'FRED',
                'unit': unit
            }
    except Exception as e:
        logger.error(f"FREDæ•°æ®è·å–å¤±è´¥ ({name}): {e}")
    return None

def update_all_indicators():
    """æ›´æ–°æ‰€æœ‰ç»æµæŒ‡æ ‡"""
    logger.info("ğŸ”„ å¼€å§‹æ›´æ–°æ‰€æœ‰ç»æµæŒ‡æ ‡...")
    data = load_data()
    
    # å®šä¹‰æŒ‡æ ‡
    indicators_config = {
        'cpi': {'fetcher': lambda: fetch_bls_data('CUUR0000SA0', 'CPIé€šèƒ€ç‡', '%')},
        'unemployment': {'fetcher': lambda: fetch_bls_data('LNS14000000', 'å¤±ä¸šç‡', '%')},
        'fed_rate': {'fetcher': lambda: fetch_fred_data('DFEDTARU', 'è”é‚¦åŸºé‡‘åˆ©ç‡', '%')},
        'ism': {'fetcher': lambda: fetch_fred_data('NAPM', 'ISMåˆ¶é€ ä¸šæŒ‡æ•°', 'ç‚¹')},
        'consumer_confidence': {'fetcher': lambda: fetch_fred_data('UMCSENT', 'æ¶ˆè´¹è€…ä¿¡å¿ƒæŒ‡æ•°', 'ç‚¹')},
    }
    
    updated = []
    
    for key, config in indicators_config.items():
        try:
            new_data = config['fetcher']()
            
            if new_data:
                if key not in data:
                    data[key] = {
                        'name': new_data['name'],
                        'unit': new_data['unit'],
                        'source': new_data['source'],
                        'data': []
                    }
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                existing_dates = [d['date'] for d in data[key]['data']]
                if new_data['date'] not in existing_dates:
                    data[key]['data'].append({
                        'month': new_data['date'][:7],
                        'value': new_data['value'],
                        'date': new_data['date']
                    })
                    data[key]['lastUpdate'] = datetime.now().isoformat()
                    updated.append(key)
                    logger.info(f"âœ… {key} å·²æ›´æ–°: {new_data['value']}")
        except Exception as e:
            logger.error(f"âŒ {key} æ›´æ–°å¤±è´¥: {e}")
    
    save_data(data)
    logger.info(f"âœ¨ æ›´æ–°å®Œæˆï¼å…±æ›´æ–° {len(updated)} ä¸ªæŒ‡æ ‡")
    return updated

# APIè·¯ç”±
@app.route('/')
def index():
    return jsonify({
        'service': 'ç¾å›½ç»æµæŒ‡æ ‡è‡ªåŠ¨çˆ¬è™«API',
        'version': '1.0.0',
        'endpoints': {
            '/api/indicators': 'è·å–æ‰€æœ‰æŒ‡æ ‡æ•°æ®',
            '/api/indicators/<name>': 'è·å–å•ä¸ªæŒ‡æ ‡æ•°æ®',
            '/api/update': 'æ‰‹åŠ¨è§¦å‘æ›´æ–°ï¼ˆPOSTï¼‰',
            '/api/status': 'æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€'
        },
        'status': 'running'
    })

@app.route('/api/indicators')
def get_all_indicators():
    data = load_data()
    return jsonify({
        'success': True,
        'data': data,
        'timestamp': datetime.now().isoformat()
    })

@app.route('/api/indicators/<name>')
def get_indicator(name):
    data = load_data()
    if name in data:
        return jsonify({
            'success': True,
            'data': data[name],
            'timestamp': datetime.now().isoformat()
        })
    return jsonify({'success': False, 'error': f'æŒ‡æ ‡ {name} ä¸å­˜åœ¨'}), 404

@app.route('/api/update', methods=['POST'])
def manual_update():
    try:
        updated = update_all_indicators()
        return jsonify({
            'success': True,
            'message': f'æˆåŠŸæ›´æ–° {len(updated)} ä¸ªæŒ‡æ ‡',
            'updated': updated
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/status')
def get_status():
    data = load_data()
    return jsonify({
        'success': True,
        'status': 'running',
        'indicators_count': len(data),
        'indicators': list(data.keys())
    })

# å®šæ—¶ä»»åŠ¡
scheduler = BackgroundScheduler()
scheduler.add_job(update_all_indicators, 'cron', hour=0, minute=0)

if __name__ == '__main__':
    logger.info("ğŸš€ ç³»ç»Ÿå¯åŠ¨ä¸­...")
    
    # åˆå§‹åŒ–æ•°æ®
    try:
        update_all_indicators()
    except Exception as e:
        logger.error(f"åˆå§‹æ›´æ–°å¤±è´¥: {e}")
    
    # å¯åŠ¨è°ƒåº¦å™¨
    scheduler.start()
    
    # å¯åŠ¨Flask
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
